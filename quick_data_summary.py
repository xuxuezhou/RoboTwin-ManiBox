#!/usr/bin/env python3
"""
å¿«é€ŸæŸ¥çœ‹integration.pklæ•°æ®æ€»ç»“
"""

import os
import torch
import numpy as np

def quick_data_summary(data_path):
    """
    å¿«é€Ÿæ•°æ®æ€»ç»“
    
    Args:
        data_path: integration.pklæ–‡ä»¶çš„è·¯å¾„
    """
    print("ğŸ“Š æ•°æ®å¿«é€Ÿæ€»ç»“")
    print("="*50)
    
    if not os.path.exists(data_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
        return
    
    try:
        # åŠ è½½æ•°æ®
        with open(data_path, 'rb') as f:
            data = torch.load(f, map_location='cpu')
        
        print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ!")
        print(f"ğŸ“ æ–‡ä»¶è·¯å¾„: {data_path}")
        print(f"ğŸ“¦ æ•°æ®é”®: {list(data.keys())}")
        
        # åŸºæœ¬ä¿¡æ¯
        print(f"\nğŸ“ˆ æ•°æ®å½¢çŠ¶:")
        for key, value in data.items():
            if isinstance(value, torch.Tensor):
                print(f"   {key}: {value.shape} ({value.dtype})")
            else:
                print(f"   {key}: {type(value)}")
        
        # æ•°æ®ç»Ÿè®¡
        print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
        for key, value in data.items():
            if isinstance(value, torch.Tensor):
                print(f"   {key}:")
                print(f"     èŒƒå›´: [{value.min():.4f}, {value.max():.4f}]")
                print(f"     å‡å€¼: {value.mean():.4f}")
                print(f"     æ ‡å‡†å·®: {value.std():.4f}")
                if torch.isnan(value).any():
                    print(f"     âš ï¸  NaNå€¼: {torch.isnan(value).sum()}")
                if torch.isinf(value).any():
                    print(f"     âš ï¸  æ— ç©·å¤§å€¼: {torch.isinf(value).sum()}")
        
        # å›¾åƒæ•°æ®è¯¦ç»†åˆ†æ
        if 'image_data' in data:
            image_data = data['image_data']
            print(f"\nğŸ¯ å›¾åƒæ•°æ®è¯¦ç»†åˆ†æ:")
            print(f"   Episodeæ•°é‡: {image_data.shape[0]}")
            print(f"   æ—¶é—´æ­¥æ•°é‡: {image_data.shape[1]}")
            print(f"   ç‰¹å¾ç»´åº¦: {image_data.shape[2]}")
            
            # åˆ†ææ¯ä¸ªç›¸æœºçš„æ£€æµ‹æƒ…å†µ
            cameras = ["head_camera", "left_camera", "right_camera"]
            for cam_idx, cam_name in enumerate(cameras):
                start_idx = cam_idx * 8
                end_idx = start_idx + 8
                cam_data = image_data[:, :, start_idx:end_idx]
                
                # è®¡ç®—æœ‰æ•ˆæ£€æµ‹ç‡
                valid_detections = (cam_data != 0).any(dim=2).float().mean()
                print(f"   {cam_name} æœ‰æ•ˆæ£€æµ‹ç‡: {valid_detections:.2%}")
        
        # çŠ¶æ€å’ŒåŠ¨ä½œæ•°æ®
        if 'qpos_data' in data and 'action_data' in data:
            print(f"\nğŸ¤– çŠ¶æ€å’ŒåŠ¨ä½œæ•°æ®:")
            print(f"   çŠ¶æ€ç»´åº¦: {data['qpos_data'].shape[-1]}")
            print(f"   åŠ¨ä½œç»´åº¦: {data['action_data'].shape[-1]}")
            
            # æ£€æŸ¥çŠ¶æ€å’ŒåŠ¨ä½œæ˜¯å¦ç›¸åŒ
            if torch.allclose(data['qpos_data'], data['action_data']):
                print(f"   âš ï¸  çŠ¶æ€å’ŒåŠ¨ä½œæ•°æ®å®Œå…¨ç›¸åŒ")
            else:
                print(f"   âœ… çŠ¶æ€å’ŒåŠ¨ä½œæ•°æ®ä¸åŒ")
        
        print(f"\n" + "="*50)
        print("âœ… æ•°æ®æ€»ç»“å®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ åŠ è½½æ•°æ®æ—¶å‡ºé”™: {e}")

def main():
    """ä¸»å‡½æ•°"""
    data_path = "/home/xuxuezhou/code/RoboTwin/data/move_can_pot/integration.pkl"
    quick_data_summary(data_path)

if __name__ == "__main__":
    main() 