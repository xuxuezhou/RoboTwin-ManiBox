/home/xuxuezhou/miniconda3/envs/RoboTwin/lib/python3.10/site-packages/ultralytics/nn/tasks.py:775: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(file, map_location="cpu")
/home/xuxuezhou/code/RoboTwin/policy/ManiBox/manibox/ManiBox/dataloader/data_load.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(os.path.join(dataset_dir, "integration.pkl"), map_location='cpu')
/home/xuxuezhou/code/RoboTwin/policy/ManiBox/manibox/ManiBox/dataloader/BBoxHistoryEpisodicDataset.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.data = torch.load(os.path.join(self.dataset_dir, "integration.pkl"), map_location='cpu')
Timestamp: 2025-07-28_03-18-09
scheduler: cos args.gradient_accumulation_steps 1
whether use acclerator: False
cur_path /home/xuxuezhou/code/RoboTwin/policy/ManiBox/manibox/ManiBox
num episodes 500
ðŸ”§ Using 2 object(s): ['apple', 'table']
ðŸ“Š Expected bbox dimension: 24

Data from: policy/ManiBox/processed_data/manibox-grasp_bottles_bimanual

Load data from policy/ManiBox/processed_data/manibox-grasp_bottles_bimanual/integration.pkl Shape:  torch.Size([500, 158, 1, 24])
image_data.shape, qpos_data.shape, action_data.shape:  torch.Size([90, 24]) torch.Size([90, 14]) torch.Size([90, 14])
Load data from policy/ManiBox/processed_data/manibox-grasp_bottles_bimanual/integration.pkl Shape:  torch.Size([500, 158, 1, 24])
image_data.shape, qpos_data.shape, action_data.shape:  torch.Size([90, 24]) torch.Size([90, 14]) torch.Size([90, 14])
length of train dataloader 4
You are using RNNPolicy.
policy_config {'lr': 0.002, 'lr_backbone': 7e-05, 'epochs': 50, 'train_loader_len': 4, 'warmup_ratio': 0.1, 'use_scheduler': 'cos', 'backbone': 'resnet18', 'masks': False, 'weight_decay': 0.0001, 'dilation': False, 'position_embedding': 'sine', 'loss_function': 'l1', 'chunk_size': 1, 'camera_names': ['cam_high', 'cam_left_wrist', 'cam_right_wrist'], 'num_next_action': 0, 'use_depth_image': False, 'use_robot_base': False, 'hidden_dim': 512, 'device': 'cuda:0', 'state_dim': 14, 'action_dim': 14, 'rnn_layers': 3, 'rnn_hidden_dim': 512, 'actor_hidden_dim': 512, 'policy_class': 'RNN', 'gradient_accumulation_steps': 1}
backbone visual encoder. number of parameters: 0.00M
temporal model. number of parameters: 5.60M
  0%|          | 0/50 [00:00<?, ?it/s]
0it [00:00, ?it/s][A
                  [A
Epoch 0, lr: 0.0004
Train loss: 0.72612
loss: 0.726 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
  2%|â–         | 1/50 [00:01<00:53,  1.08s/it]Best ckpt saved, val loss 0.699789 @ epoch0
Val loss:   0.69979.   Best val loss: 0.69979 at epoch 0
loss: 0.700 

Epoch 1, lr: 0.0008
Train loss: 0.66210
loss: 0.662 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
  4%|â–         | 2/50 [00:01<00:43,  1.12it/s]Best ckpt saved, val loss 0.372541 @ epoch1
Val loss:   0.37254.   Best val loss: 0.37254 at epoch 1
loss: 0.373 

Epoch 2, lr: 0.0012
Train loss: 0.34090
loss: 0.341 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
  6%|â–Œ         | 3/50 [00:02<00:38,  1.22it/s]Best ckpt saved, val loss 0.288225 @ epoch2
Val loss:   0.28822.   Best val loss: 0.28822 at epoch 2
loss: 0.288 

Epoch 3, lr: 0.0016
Train loss: 0.27724
loss: 0.277 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
  8%|â–Š         | 4/50 [00:03<00:36,  1.27it/s]Best ckpt saved, val loss 0.255029 @ epoch3
Val loss:   0.25503.   Best val loss: 0.25503 at epoch 3
loss: 0.255 

Epoch 4, lr: 0.002
Train loss: 0.24647
loss: 0.246 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 10%|â–ˆ         | 5/50 [00:04<00:34,  1.29it/s]Best ckpt saved, val loss 0.237844 @ epoch4
Val loss:   0.23784.   Best val loss: 0.23784 at epoch 4
loss: 0.238 

Epoch 5, lr: 0.0019975640502598244
Train loss: 0.22567
loss: 0.226 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 12%|â–ˆâ–        | 6/50 [00:04<00:33,  1.31it/s]Best ckpt saved, val loss 0.207197 @ epoch5
Val loss:   0.20720.   Best val loss: 0.20720 at epoch 5
loss: 0.207 

Epoch 6, lr: 0.0019902680687415705
Train loss: 0.21020
loss: 0.210 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 14%|â–ˆâ–        | 7/50 [00:05<00:32,  1.32it/s]Best ckpt saved, val loss 0.197338 @ epoch6
Val loss:   0.19734.   Best val loss: 0.19734 at epoch 6
loss: 0.197 

Epoch 7, lr: 0.0019781476007338056
Train loss: 0.19601
loss: 0.196 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 16%|â–ˆâ–Œ        | 8/50 [00:06<00:31,  1.32it/s]Best ckpt saved, val loss 0.195034 @ epoch7
Val loss:   0.19503.   Best val loss: 0.19503 at epoch 7
loss: 0.195 

Epoch 8, lr: 0.001961261695938319
Train loss: 0.18977
loss: 0.190 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 18%|â–ˆâ–Š        | 9/50 [00:07<00:34,  1.19it/s]Best ckpt saved, val loss 0.185842 @ epoch8
Val loss:   0.18584.   Best val loss: 0.18584 at epoch 8
loss: 0.186 

Epoch 9, lr: 0.0019396926207859084
Train loss: 0.18422
loss: 0.184 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 20%|â–ˆâ–ˆ        | 10/50 [00:08<00:32,  1.24it/s]Val loss:   0.19042.   Best val loss: 0.18584 at epoch 8
loss: 0.190 

Epoch 10, lr: 0.001913545457642601
Train loss: 0.17961
loss: 0.180 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 22%|â–ˆâ–ˆâ–       | 11/50 [00:08<00:30,  1.26it/s]Best ckpt saved, val loss 0.167073 @ epoch10
Val loss:   0.16707.   Best val loss: 0.16707 at epoch 10
loss: 0.167 

Epoch 11, lr: 0.001882947592858927
Train loss: 0.16434
loss: 0.164 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 24%|â–ˆâ–ˆâ–       | 12/50 [00:09<00:29,  1.27it/s]Best ckpt saved, val loss 0.158051 @ epoch11
Val loss:   0.15805.   Best val loss: 0.15805 at epoch 11
loss: 0.158 

Epoch 12, lr: 0.0018480480961564258
Train loss: 0.15374
loss: 0.154 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 26%|â–ˆâ–ˆâ–Œ       | 13/50 [00:10<00:28,  1.28it/s]Best ckpt saved, val loss 0.155049 @ epoch12
Val loss:   0.15505.   Best val loss: 0.15505 at epoch 12
loss: 0.155 

Epoch 13, lr: 0.0018090169943749475
Train loss: 0.15398
loss: 0.154 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 28%|â–ˆâ–ˆâ–Š       | 14/50 [00:11<00:28,  1.25it/s]Best ckpt saved, val loss 0.150023 @ epoch13
Val loss:   0.15002.   Best val loss: 0.15002 at epoch 13
loss: 0.150 

Epoch 14, lr: 0.001766044443118978
Train loss: 0.14898
loss: 0.149 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 30%|â–ˆâ–ˆâ–ˆ       | 15/50 [00:12<00:27,  1.25it/s]Best ckpt saved, val loss 0.147428 @ epoch14
Val loss:   0.14743.   Best val loss: 0.14743 at epoch 14
loss: 0.147 

Epoch 15, lr: 0.001719339800338651
Train loss: 0.14698
loss: 0.147 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 32%|â–ˆâ–ˆâ–ˆâ–      | 16/50 [00:12<00:27,  1.25it/s]Best ckpt saved, val loss 0.142500 @ epoch15
Val loss:   0.14250.   Best val loss: 0.14250 at epoch 15
loss: 0.143 

Epoch 16, lr: 0.0016691306063588583
Train loss: 0.14409
loss: 0.144 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 34%|â–ˆâ–ˆâ–ˆâ–      | 17/50 [00:13<00:26,  1.24it/s]Best ckpt saved, val loss 0.141504 @ epoch16
Val loss:   0.14150.   Best val loss: 0.14150 at epoch 16
loss: 0.142 

Epoch 17, lr: 0.0016156614753256582
Train loss: 0.14361
loss: 0.144 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 18/50 [00:14<00:26,  1.22it/s]Best ckpt saved, val loss 0.139372 @ epoch17
Val loss:   0.13937.   Best val loss: 0.13937 at epoch 17
loss: 0.139 

Epoch 18, lr: 0.0015591929034707468
Train loss: 0.14211
loss: 0.142 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 19/50 [00:15<00:25,  1.23it/s]Best ckpt saved, val loss 0.137866 @ epoch18
Val loss:   0.13787.   Best val loss: 0.13787 at epoch 18
loss: 0.138 

Epoch 19, lr: 0.0015
Train loss: 0.13907
loss: 0.139 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [00:16<00:24,  1.23it/s]Val loss:   0.13798.   Best val loss: 0.13787 at epoch 18
loss: 0.138 
/home/xuxuezhou/code/RoboTwin/policy/ManiBox/manibox/ManiBox/train.py:145: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  plt.figure()

Epoch 20, lr: 0.0014383711467890773
Train loss: 0.14083
loss: 0.141 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/50 [00:16<00:23,  1.26it/s]Val loss:   0.13964.   Best val loss: 0.13787 at epoch 18
loss: 0.140 

Epoch 21, lr: 0.0013746065934159121
Train loss: 0.13811
loss: 0.138 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/50 [00:17<00:22,  1.25it/s]Best ckpt saved, val loss 0.134781 @ epoch21
Val loss:   0.13478.   Best val loss: 0.13478 at epoch 21
loss: 0.135 

Epoch 22, lr: 0.0013090169943749475
Train loss: 0.13526
loss: 0.135 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 23/50 [00:18<00:21,  1.24it/s]Best ckpt saved, val loss 0.134271 @ epoch22
Val loss:   0.13427.   Best val loss: 0.13427 at epoch 22
loss: 0.134 

Epoch 23, lr: 0.0012419218955996676
Train loss: 0.13371
loss: 0.134 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 24/50 [00:19<00:21,  1.23it/s]Best ckpt saved, val loss 0.129416 @ epoch23
Val loss:   0.12942.   Best val loss: 0.12942 at epoch 23
loss: 0.129 

Epoch 24, lr: 0.0011736481776669307
Train loss: 0.13314
loss: 0.133 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/50 [00:20<00:20,  1.22it/s]Best ckpt saved, val loss 0.129411 @ epoch24
Val loss:   0.12941.   Best val loss: 0.12941 at epoch 24
loss: 0.129 

Epoch 25, lr: 0.0011045284632676536
Train loss: 0.13037
loss: 0.130 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/50 [00:21<00:20,  1.19it/s]Best ckpt saved, val loss 0.128915 @ epoch25
Val loss:   0.12892.   Best val loss: 0.12892 at epoch 25
loss: 0.129 

Epoch 26, lr: 0.0010348994967025011
Train loss: 0.12993
loss: 0.130 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 27/50 [00:21<00:19,  1.18it/s]Best ckpt saved, val loss 0.128596 @ epoch26
Val loss:   0.12860.   Best val loss: 0.12860 at epoch 26
loss: 0.129 

Epoch 27, lr: 0.0009651005032974994
Train loss: 0.12853
loss: 0.129 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 28/50 [00:22<00:18,  1.18it/s]Best ckpt saved, val loss 0.126021 @ epoch27
Val loss:   0.12602.   Best val loss: 0.12602 at epoch 27
loss: 0.126 

Epoch 28, lr: 0.0008954715367323467
Train loss: 0.12722
loss: 0.127 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 29/50 [00:23<00:17,  1.17it/s]Best ckpt saved, val loss 0.123579 @ epoch28
Val loss:   0.12358.   Best val loss: 0.12358 at epoch 28
loss: 0.124 

Epoch 29, lr: 0.0008263518223330697
Train loss: 0.12617
loss: 0.126 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [00:24<00:16,  1.18it/s]Best ckpt saved, val loss 0.122299 @ epoch29
Val loss:   0.12230.   Best val loss: 0.12230 at epoch 29
loss: 0.122 

Epoch 30, lr: 0.0007580781044003324
Train loss: 0.12468
loss: 0.125 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/50 [00:25<00:17,  1.11it/s]Best ckpt saved, val loss 0.120553 @ epoch30
Val loss:   0.12055.   Best val loss: 0.12055 at epoch 30
loss: 0.121 

Epoch 31, lr: 0.0006909830056250527
Train loss: 0.12236
loss: 0.122 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 32/50 [00:26<00:16,  1.12it/s]Best ckpt saved, val loss 0.119978 @ epoch31
Val loss:   0.11998.   Best val loss: 0.11998 at epoch 31
loss: 0.120 

Epoch 32, lr: 0.0006253934065840879
Train loss: 0.12096
loss: 0.121 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 33/50 [00:27<00:15,  1.13it/s]Best ckpt saved, val loss 0.116695 @ epoch32
Val loss:   0.11670.   Best val loss: 0.11670 at epoch 32
loss: 0.117 

Epoch 33, lr: 0.0005616288532109225
Train loss: 0.11973
loss: 0.120 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 34/50 [00:28<00:13,  1.14it/s]Best ckpt saved, val loss 0.114978 @ epoch33
Val loss:   0.11498.   Best val loss: 0.11498 at epoch 33
loss: 0.115 

Epoch 34, lr: 0.0005000000000000002
Train loss: 0.11654
loss: 0.117 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 35/50 [00:28<00:13,  1.14it/s]Best ckpt saved, val loss 0.110077 @ epoch34
Val loss:   0.11008.   Best val loss: 0.11008 at epoch 34
loss: 0.110 

Epoch 35, lr: 0.0004408070965292533
Train loss: 0.11230
loss: 0.112 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 36/50 [00:29<00:12,  1.14it/s]Best ckpt saved, val loss 0.106439 @ epoch35
Val loss:   0.10644.   Best val loss: 0.10644 at epoch 35
loss: 0.106 

Epoch 36, lr: 0.0003843385246743417
Train loss: 0.10863
loss: 0.109 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 37/50 [00:30<00:11,  1.14it/s]Best ckpt saved, val loss 0.102658 @ epoch36
Val loss:   0.10266.   Best val loss: 0.10266 at epoch 36
loss: 0.103 

Epoch 37, lr: 0.0003308693936411421
Train loss: 0.10552
loss: 0.106 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 38/50 [00:31<00:10,  1.13it/s]Best ckpt saved, val loss 0.098468 @ epoch37
Val loss:   0.09847.   Best val loss: 0.09847 at epoch 37
loss: 0.098 

Epoch 38, lr: 0.00028066019966134904
Train loss: 0.10266
loss: 0.103 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 39/50 [00:32<00:09,  1.13it/s]Best ckpt saved, val loss 0.094896 @ epoch38
Val loss:   0.09490.   Best val loss: 0.09490 at epoch 38
loss: 0.095 

Epoch 39, lr: 0.0002339555568810221
Train loss: 0.09948
loss: 0.099 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40/50 [00:33<00:08,  1.13it/s]Best ckpt saved, val loss 0.091724 @ epoch39
Val loss:   0.09172.   Best val loss: 0.09172 at epoch 39
loss: 0.092 

Epoch 40, lr: 0.00019098300562505265
Train loss: 0.09607
loss: 0.096 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 41/50 [00:34<00:07,  1.13it/s]Best ckpt saved, val loss 0.088134 @ epoch40
Val loss:   0.08813.   Best val loss: 0.08813 at epoch 40
loss: 0.088 

Epoch 41, lr: 0.00015195190384357404
Train loss: 0.09411
loss: 0.094 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 42/50 [00:35<00:07,  1.12it/s]Best ckpt saved, val loss 0.085453 @ epoch41
Val loss:   0.08545.   Best val loss: 0.08545 at epoch 41
loss: 0.085 

Epoch 42, lr: 0.00011705240714107302
Train loss: 0.09098
loss: 0.091 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 43/50 [00:36<00:06,  1.13it/s]Best ckpt saved, val loss 0.083188 @ epoch42
Val loss:   0.08319.   Best val loss: 0.08319 at epoch 42
loss: 0.083 

Epoch 43, lr: 8.645454235739902e-05
Train loss: 0.09008
loss: 0.090 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 44/50 [00:36<00:05,  1.12it/s]Best ckpt saved, val loss 0.081273 @ epoch43
Val loss:   0.08127.   Best val loss: 0.08127 at epoch 43
loss: 0.081 

Epoch 44, lr: 6.0307379214091684e-05
Train loss: 0.08782
loss: 0.088 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 45/50 [00:37<00:04,  1.11it/s]Best ckpt saved, val loss 0.079430 @ epoch44
Val loss:   0.07943.   Best val loss: 0.07943 at epoch 44
loss: 0.079 

Epoch 45, lr: 3.873830406168111e-05
Train loss: 0.08825
loss: 0.088 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 46/50 [00:38<00:03,  1.10it/s]Best ckpt saved, val loss 0.078295 @ epoch45
Val loss:   0.07830.   Best val loss: 0.07830 at epoch 45
loss: 0.078 

Epoch 46, lr: 2.1852399266194312e-05
Train loss: 0.08542
loss: 0.085 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 47/50 [00:39<00:02,  1.11it/s]Best ckpt saved, val loss 0.077659 @ epoch46
Val loss:   0.07766.   Best val loss: 0.07766 at epoch 46
loss: 0.078 

Epoch 47, lr: 9.731931258429638e-06
Train loss: 0.08566
loss: 0.086 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 48/50 [00:40<00:01,  1.09it/s]Best ckpt saved, val loss 0.077219 @ epoch47
Val loss:   0.07722.   Best val loss: 0.07722 at epoch 47
loss: 0.077 

Epoch 48, lr: 2.4359497401758024e-06
Train loss: 0.08590
loss: 0.086 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 49/50 [00:41<00:00,  1.09it/s]Best ckpt saved, val loss 0.077053 @ epoch48
Val loss:   0.07705.   Best val loss: 0.07705 at epoch 48
loss: 0.077 

Epoch 49, lr: 0.0
Train loss: 0.08557
loss: 0.086 
Saved plots to ./ckpt/2025-07-28_03-18-09RNN
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:42<00:00,  1.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:42<00:00,  1.18it/s]
