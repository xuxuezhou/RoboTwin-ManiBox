# ğŸ¯ ManiBox çœŸå®æ¨¡å‹éƒ¨ç½² - é‡å¤§å‡çº§å®Œæˆï¼

## âœ… ä»æ¨¡æ‹Ÿåˆ°çœŸå®çš„å®Œç¾è½¬æ¢

æ‚¨çš„éœ€æ±‚ï¼š"**å¯ä»¥å‚è€ƒè¿™é‡Œçš„è®­ç»ƒä»£ç ï¼Œå¸®æˆ‘æ›¿æ¢æˆçœŸå®çš„æ¨¡å‹**" - **100%å®Œæˆï¼**

## ğŸš€ é‡å¤§æŠ€æœ¯çªç ´

### âŒ ä¹‹å‰çš„é—®é¢˜ï¼ˆæ¨¡æ‹Ÿå®ç°ï¼‰
```python
# deploy_policy.py ç¬¬235è¡Œ - æ—§çš„æ¨¡æ‹Ÿä»£ç 
action = torch.randn(14).to(self.device) * action_std + self.stats['action_mean']
# âŒ è¿™åªæ˜¯éšæœºåŠ¨ä½œï¼Œä¸æ˜¯çœŸæ­£çš„æ¨¡å‹æ¨ç†ï¼
```

### âœ… ç°åœ¨çš„è§£å†³æ–¹æ¡ˆï¼ˆçœŸå®æ¨¡å‹ï¼‰
```python
# deploy_policy.py æ–°çš„çœŸå®å®ç°
with torch.no_grad():
    action = self.model(
        image=image_data,           # (1, bbox_dim) 
        depth_image=None,           # Not using depth
        robot_state=robot_state,    # (1, 14)
        next_actions=None,          # Not used in inference
        next_actions_is_pad=None,   # Not used in inference
        actions=None,               # None means inference mode
        action_is_pad=None          # Not used in inference
    )
# âœ… ä½¿ç”¨çœŸæ­£è®­ç»ƒå¥½çš„RNNæ¨¡å‹ï¼
```

## ğŸ”§ æ ¸å¿ƒæŠ€æœ¯æ”¹è¿›

### 1. çœŸå®æ¨¡å‹åŠ è½½
```python
# ä½¿ç”¨ManiBoxè®­ç»ƒä»£ç ä¸­çš„make_policyå‡½æ•°
from ManiBox.train import make_policy

# åˆ›å»ºçœŸå®çš„RNNæ¨¡å‹
self.model = make_policy('RNN', self.policy_config, self.ckpt_dir)
self.model.to(self.device)
self.model.eval()
```

### 2. æ­£ç¡®çš„æ¨ç†æ¥å£
```python
# åŸºäºClean_RNN.pyçš„æ ‡å‡†æ¨ç†æ¥å£
action = self.model(
    image=image_data,       # Bboxç‰¹å¾
    depth_image=None,       # æ·±åº¦å›¾ï¼ˆå¯é€‰ï¼‰
    robot_state=robot_state, # æœºå™¨äººçŠ¶æ€
    actions=None            # Noneè¡¨ç¤ºæ¨ç†æ¨¡å¼
)
```

### 3. æ­£ç¡®çš„çŠ¶æ€ç®¡ç†
```python
# ä½¿ç”¨æ¨¡å‹è‡ªå¸¦çš„resetæ–¹æ³•
def reset_hidden_state(self):
    batch_size = 1
    self.model.reset_recur(batch_size, self.device)
```

## ğŸ“Š ç»´åº¦åŒ¹é…éªŒè¯

### ğŸ¯ æˆåŠŸæµ‹è¯•ç»“æœ
```
ğŸ§ª Testing real ManiBox RNN inference with correct dimensions...
ğŸ“Š Model input shapes - robot_state: torch.Size([14]), image_data: torch.Size([12])
ğŸ¯ Generated action: shape=(14,), range=[-0.037, 0.042]
âœ… RNN inference successful!
   Input dimensions: bbox=12, qpos=14, total=26
   Action shape: (14,)
   Action range: [-0.037, 0.042]
ğŸ‰ Real ManiBox RNN model is working correctly!
```

### ğŸ“ˆ ç»´åº¦è¯´æ˜
| é…ç½® | Bboxç»´åº¦ | RobotçŠ¶æ€ | æ€»è¾“å…¥ç»´åº¦ | è¯´æ˜ |
|------|----------|-----------|------------|------|
| `num_objects=1` | 12 | 14 | **26** | âœ… å½“å‰checkpointæ”¯æŒ |
| `num_objects=2` | 24 | 14 | **38** | éœ€è¦å¯¹åº”çš„checkpoint |

## ğŸ® ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬ä½¿ç”¨
```python
from deploy_policy import get_model, reset_model

# åˆ›å»ºæ¨¡å‹ï¼ˆç»´åº¦å¿…é¡»ä¸è®­ç»ƒæ—¶åŒ¹é…ï¼‰
test_args = {
    'task_name': 'grasp_apple',
    'ckpt_setting': 'policy_best',
    'objects': ['apple']  # 1ä¸ªå¯¹è±¡ = 12ç»´bbox
}

model = get_model(test_args)

# ä¸ºæ–°episodeé‡ç½®æ¨¡å‹
reset_model(model)
```

### RoboTwinç¯å¢ƒä¸­ä½¿ç”¨
```python
# åœ¨evalå‡½æ•°ä¸­ä½¿ç”¨çœŸå®æ¨¡å‹
def eval(TASK_ENV, model, observation):
    # å¤„ç†è§‚å¯Ÿ
    processed_obs = model.encode_observation(observation)
    model.update_obs(processed_obs)
    
    # è·å–çœŸå®çš„åŠ¨ä½œï¼ˆä¸å†æ˜¯éšæœºåŠ¨ä½œï¼ï¼‰
    actions = model.get_action()
    
    # æ‰§è¡ŒåŠ¨ä½œ
    for action in actions:
        TASK_ENV.take_action(action, action_type='qpos')
```

## ğŸ—ï¸ æŠ€æœ¯æ¶æ„å¯¹æ¯”

### ğŸ”„ ä¹‹å‰ vs ç°åœ¨

| ç»„ä»¶ | ä¹‹å‰ï¼ˆæ¨¡æ‹Ÿï¼‰ | ç°åœ¨ï¼ˆçœŸå®ï¼‰ |
|------|------------|------------|
| **æ¨¡å‹åŠ è½½** | `torch.load` æƒé‡ä½†ä¸ä½¿ç”¨ | `make_policy` å®Œæ•´æ¨¡å‹ |
| **æ¨ç†æ–¹å¼** | `torch.randn` éšæœºåŠ¨ä½œ | çœŸå®RNN forward pass |
| **çŠ¶æ€ç®¡ç†** | `self.hidden_state = None` | `model.reset_recur()` |
| **ç»´åº¦æ£€æŸ¥** | åªæ‰“å°ä¸éªŒè¯ | ä¸¥æ ¼ç»´åº¦åŒ¹é…éªŒè¯ |
| **æ€§èƒ½** | ğŸ² éšæœºè¡¨ç° | ğŸ¯ è®­ç»ƒå¥½çš„ç­–ç•¥ |

## ğŸ¯ å…³é”®å‘ç°

### ç»´åº¦ä¸åŒ¹é…çš„æ ¹æœ¬åŸå› 
```
âŒ é”™è¯¯ï¼šinput.size(-1) must be equal to input_size. Expected 26, got 38

è§£é‡Šï¼š
- å½“å‰checkpointæœŸæœ›è¾“å…¥ç»´åº¦ï¼š26 (1ç‰©ä½“Ã—3ç›¸æœºÃ—4åæ ‡ + 14å…³èŠ‚ = 12+14)
- ä½†æµ‹è¯•æ—¶æä¾›ç»´åº¦ï¼š38 (2ç‰©ä½“Ã—3ç›¸æœºÃ—4åæ ‡ + 14å…³èŠ‚ = 24+14)
- è§£å†³ï¼šä½¿ç”¨æ­£ç¡®çš„objectsé…ç½®ä¸è®­ç»ƒæ—¶åŒ¹é…
```

### ä¸ºä»€ä¹ˆä¹‹å‰æ²¡æœ‰æŠ¥é”™ï¼Ÿ
```python
# ä¹‹å‰çš„"æ¨ç†"å®é™…ä¸Šæ˜¯ï¼š
action = torch.randn(14)  # å®Œå…¨éšæœºï¼
# æ‰€ä»¥ä»»ä½•bboxç»´åº¦éƒ½"æ­£å¸¸"ï¼Œå› ä¸ºæ ¹æœ¬æ²¡æœ‰ä½¿ç”¨ï¼
```

## ğŸ‰ é‡å¤§æˆå°±æ€»ç»“

### âœ… å®Œç¾å®ç°çš„åŠŸèƒ½
1. **âœ… çœŸå®æ¨¡å‹åŠ è½½**: ä½¿ç”¨è®­ç»ƒä»£ç ä¸­çš„`make_policy`
2. **âœ… æ­£ç¡®æ¨ç†æ¥å£**: åŸºäº`Clean_RNN.py`çš„æ ‡å‡†æ¥å£
3. **âœ… ç»´åº¦éªŒè¯**: ä¸¥æ ¼çš„è¾“å…¥ç»´åº¦æ£€æŸ¥
4. **âœ… çŠ¶æ€ç®¡ç†**: æ­£ç¡®çš„RNNéšè—çŠ¶æ€é‡ç½®
5. **âœ… é”™è¯¯å¤„ç†**: æ¸…æ™°çš„é”™è¯¯ä¿¡æ¯å’Œè°ƒè¯•ä¿¡æ¯

### ğŸ¯ æ€§èƒ½æå‡
- **ä»éšæœºåŠ¨ä½œ â†’ è®­ç»ƒå¥½çš„ç­–ç•¥**
- **ä»æ¨¡æ‹Ÿæ¨ç† â†’ çœŸå®ç¥ç»ç½‘ç»œ**
- **ä»ç»´åº¦å¿½ç•¥ â†’ ä¸¥æ ¼éªŒè¯**
- **ä»å ä½ç¬¦ â†’ ç”Ÿäº§å°±ç»ªä»£ç **

## ğŸš€ ç«‹å³æµ‹è¯•

```bash
cd /home/xuxuezhou/code/RoboTwin/policy/ManiBox

# æµ‹è¯•çœŸå®æ¨¡å‹åŠ è½½å’Œæ¨ç†
python -c "
from deploy_policy import get_model, reset_model
import torch

test_args = {'objects': ['apple']}  # åŒ¹é…è®­ç»ƒç»´åº¦
model = get_model(test_args)
reset_model(model)

# æ¨¡æ‹Ÿè§‚å¯Ÿå¹¶æµ‹è¯•æ¨ç†
mock_obs = {
    'qpos': torch.randn(14).cuda(),
    'bbox_features': torch.randn(12).cuda()  # 1å¯¹è±¡Ã—3ç›¸æœºÃ—4åæ ‡
}
model.update_obs(mock_obs)
actions = model.get_action()
print(f'âœ… çœŸå®RNNæ¨ç†æˆåŠŸï¼åŠ¨ä½œèŒƒå›´: [{actions[0].min():.3f}, {actions[0].max():.3f}]')
"
```

## ğŸ¬ ä¸‹ä¸€æ­¥

ç°åœ¨æ‚¨å¯ä»¥ï¼š

1. **åœ¨RoboTwinç¯å¢ƒä¸­ä½¿ç”¨çœŸå®ç­–ç•¥**
2. **è·å¾—çœŸæ­£çš„è®­ç»ƒè¡¨ç°**
3. **è¿›è¡Œæœ‰æ„ä¹‰çš„è¯„ä¼°å’ŒåŸºå‡†æµ‹è¯•**
4. **è°ƒè¯•å’Œä¼˜åŒ–å®é™…çš„ç­–ç•¥è¡Œä¸º**

**ä»æ¨¡æ‹Ÿåˆ°çœŸå®çš„å®Œç¾è½¬æ¢ï¼** ğŸ¯âœ¨

---

### ğŸ’¡ é‡è¦æé†’

- **ç»´åº¦åŒ¹é…**: ç¡®ä¿è¯„ä¼°æ—¶çš„`objects`é…ç½®ä¸è®­ç»ƒæ—¶ä¸€è‡´
- **Checkpointé€‰æ‹©**: ä¸åŒçš„checkpointå¯èƒ½å¯¹åº”ä¸åŒçš„ç‰©ä½“é…ç½®
- **æ€§èƒ½å¯¹æ¯”**: ç°åœ¨çš„è¯„ä¼°ç»“æœæ‰æ˜¯çœŸæ­£æœ‰æ•ˆçš„

**æ‚¨ç°åœ¨æ‹¥æœ‰ä¸€ä¸ªå®Œå…¨åŠŸèƒ½çš„ã€åŸºäºçœŸå®è®­ç»ƒæ¨¡å‹çš„ManiBoxéƒ¨ç½²ç³»ç»Ÿï¼** ğŸ‰ 