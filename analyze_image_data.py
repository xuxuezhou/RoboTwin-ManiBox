#!/usr/bin/env python3
"""
ä¸“é—¨åˆ†æintegration.pklä¸­å›¾åƒæ•°æ®ç»“æ„çš„è„šæœ¬
"""

import os
import torch
import numpy as np

def analyze_image_data_structure(data_path):
    """
    åˆ†æå›¾åƒæ•°æ®çš„è¯¦ç»†ç»“æ„
    
    Args:
        data_path: integration.pklæ–‡ä»¶çš„è·¯å¾„
    """
    print("ğŸ” åˆ†æå›¾åƒæ•°æ®ç»“æ„...")
    print(f"ğŸ“ æ•°æ®è·¯å¾„: {data_path}")
    
    if not os.path.exists(data_path):
        print(f"âŒ é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨ - {data_path}")
        return
    
    try:
        # åŠ è½½æ•°æ®
        with open(data_path, 'rb') as f:
            data = torch.load(f, map_location='cpu')
        
        image_data = data['image_data']
        print("âœ… å›¾åƒæ•°æ®åŠ è½½æˆåŠŸ!")
        print("\n" + "="*60)
        
        # åŸºæœ¬ä¿¡æ¯
        print("ğŸ“Š å›¾åƒæ•°æ®åŸºæœ¬ä¿¡æ¯:")
        print(f"   å½¢çŠ¶: {image_data.shape}")
        print(f"   æ•°æ®ç±»å‹: {image_data.dtype}")
        print(f"   Episodeæ•°é‡: {image_data.shape[0]}")
        print(f"   æ—¶é—´æ­¥æ•°é‡: {image_data.shape[1]}")
        print(f"   ç‰¹å¾ç»´åº¦: {image_data.shape[2]}")
        
        # åˆ†æç‰¹å¾ç»´åº¦ç»“æ„
        print(f"\nğŸ” ç‰¹å¾ç»´åº¦åˆ†æ (24ç»´):")
        print("   æ ¹æ®process_data.pyï¼Œè¿™24ç»´æ•°æ®åŒ…å«:")
        print("   - 3ä¸ªç›¸æœº (head_camera, left_camera, right_camera)")
        print("   - æ¯ä¸ªç›¸æœº2ä¸ªæ£€æµ‹ (max_detections_per_object=2)")
        print("   - æ¯ä¸ªæ£€æµ‹4ä¸ªåæ ‡ (x1, y1, x2, y2) - xyxynæ ¼å¼")
        print("   - æ€»è®¡: 3 Ã— 2 Ã— 4 = 24ç»´")
        
        # åˆ†ææ¯ä¸ªç›¸æœºçš„æ•°æ®
        print(f"\nğŸ“· ç›¸æœºæ•°æ®åˆ†å¸ƒ:")
        cameras = ["head_camera", "left_camera", "right_camera"]
        detections_per_camera = 2
        coords_per_detection = 4
        
        for cam_idx, cam_name in enumerate(cameras):
            start_idx = cam_idx * detections_per_camera * coords_per_detection
            end_idx = start_idx + detections_per_camera * coords_per_detection
            
            print(f"\n   {cam_name}:")
            print(f"     ç´¢å¼•èŒƒå›´: {start_idx} - {end_idx-1}")
            print(f"     æ•°æ®ç»´åº¦: {detections_per_camera} ä¸ªæ£€æµ‹ Ã— {coords_per_detection} ä¸ªåæ ‡")
            
            # åˆ†æè¿™ä¸ªç›¸æœºçš„æ•°æ®
            cam_data = image_data[:, :, start_idx:end_idx]
            print(f"     æ•°æ®å½¢çŠ¶: {cam_data.shape}")
            print(f"     æ•°å€¼èŒƒå›´: [{cam_data.min():.6f}, {cam_data.max():.6f}]")
            print(f"     éé›¶å€¼æ¯”ä¾‹: {(cam_data != 0).float().mean():.2%}")
            
            # æ˜¾ç¤ºä¸€äº›æ ·æœ¬
            print(f"     æ ·æœ¬æ•°æ® (Episode 1, æ—¶é—´æ­¥ 1):")
            sample = cam_data[0, 0].reshape(detections_per_camera, coords_per_detection)
            for det_idx in range(detections_per_camera):
                bbox = sample[det_idx]
                if torch.all(bbox == 0):
                    print(f"        æ£€æµ‹ {det_idx+1}: [0, 0, 0, 0] (æ— æ£€æµ‹)")
                else:
                    print(f"        æ£€æµ‹ {det_idx+1}: [{bbox[0]:.4f}, {bbox[1]:.4f}, {bbox[2]:.4f}, {bbox[3]:.4f}]")
        
        # åˆ†ææ£€æµ‹è´¨é‡
        print(f"\nğŸ“ˆ æ£€æµ‹è´¨é‡åˆ†æ:")
        
        # ç»Ÿè®¡æœ‰æ•ˆæ£€æµ‹æ•°é‡
        total_detections = 0
        valid_detections = 0
        
        for ep in range(min(5, image_data.shape[0])):  # åˆ†æå‰5ä¸ªepisode
            for t in range(min(10, image_data.shape[1])):  # åˆ†æå‰10ä¸ªæ—¶é—´æ­¥
                for cam_idx in range(3):
                    start_idx = cam_idx * 8
                    end_idx = start_idx + 8
                    cam_data = image_data[ep, t, start_idx:end_idx].reshape(2, 4)
                    
                    for det_idx in range(2):
                        bbox = cam_data[det_idx]
                        total_detections += 1
                        if not torch.all(bbox == 0):
                            valid_detections += 1
        
        detection_rate = valid_detections / total_detections if total_detections > 0 else 0
        print(f"   æœ‰æ•ˆæ£€æµ‹ç‡: {detection_rate:.2%}")
        print(f"   æ€»æ£€æµ‹æ¬¡æ•°: {total_detections}")
        print(f"   æœ‰æ•ˆæ£€æµ‹æ¬¡æ•°: {valid_detections}")
        
        # åˆ†æè¾¹ç•Œæ¡†åæ ‡åˆ†å¸ƒ
        print(f"\nğŸ“ è¾¹ç•Œæ¡†åæ ‡åˆ†æ:")
        
        # æ”¶é›†æ‰€æœ‰éé›¶è¾¹ç•Œæ¡†
        valid_bboxes = []
        for ep in range(image_data.shape[0]):
            for t in range(image_data.shape[1]):
                for cam_idx in range(3):
                    start_idx = cam_idx * 8
                    end_idx = start_idx + 8
                    cam_data = image_data[ep, t, start_idx:end_idx].reshape(2, 4)
                    
                    for det_idx in range(2):
                        bbox = cam_data[det_idx]
                        if not torch.all(bbox == 0):
                            valid_bboxes.append(bbox.numpy())
        
        if valid_bboxes:
            valid_bboxes = np.array(valid_bboxes)
            print(f"   æœ‰æ•ˆè¾¹ç•Œæ¡†æ•°é‡: {len(valid_bboxes)}")
            print(f"   x1 èŒƒå›´: [{valid_bboxes[:, 0].min():.4f}, {valid_bboxes[:, 0].max():.4f}]")
            print(f"   y1 èŒƒå›´: [{valid_bboxes[:, 1].min():.4f}, {valid_bboxes[:, 1].max():.4f}]")
            print(f"   x2 èŒƒå›´: [{valid_bboxes[:, 2].min():.4f}, {valid_bboxes[:, 2].max():.4f}]")
            print(f"   y2 èŒƒå›´: [{valid_bboxes[:, 3].min():.4f}, {valid_bboxes[:, 3].max():.4f}]")
            
            # æ£€æŸ¥è¾¹ç•Œæ¡†åˆç†æ€§
            invalid_bboxes = 0
            for bbox in valid_bboxes:
                x1, y1, x2, y2 = bbox
                if x1 >= x2 or y1 >= y2 or x1 < 0 or y1 < 0 or x2 > 1 or y2 > 1:
                    invalid_bboxes += 1
            
            print(f"   ä¸åˆç†è¾¹ç•Œæ¡†æ•°é‡: {invalid_bboxes}")
            print(f"   ä¸åˆç†æ¯”ä¾‹: {invalid_bboxes/len(valid_bboxes):.2%}")
        
        # æ—¶é—´åºåˆ—åˆ†æ
        print(f"\nâ° æ—¶é—´åºåˆ—åˆ†æ:")
        
        # åˆ†ææ£€æµ‹è¿ç»­æ€§
        continuity_analysis = []
        for ep in range(min(3, image_data.shape[0])):
            ep_continuity = []
            for cam_idx in range(3):
                start_idx = cam_idx * 8
                end_idx = start_idx + 8
                cam_data = image_data[ep, :, start_idx:end_idx].reshape(-1, 2, 4)
                
                # æ£€æŸ¥æ¯ä¸ªæ£€æµ‹æ§½ä½çš„è¿ç»­æ€§
                for det_idx in range(2):
                    det_series = cam_data[:, det_idx]
                    valid_frames = torch.any(det_series != 0, dim=1)
                    continuity = valid_frames.float().mean()
                    ep_continuity.append(continuity.item())
            
            continuity_analysis.append(ep_continuity)
            print(f"   Episode {ep+1} æ£€æµ‹è¿ç»­æ€§:")
            for cam_idx, cam_name in enumerate(cameras):
                for det_idx in range(2):
                    continuity = ep_continuity[cam_idx * 2 + det_idx]
                    print(f"     {cam_name} æ£€æµ‹{det_idx+1}: {continuity:.2%}")
        
        print(f"\n" + "="*60)
        print("âœ… å›¾åƒæ•°æ®ç»“æ„åˆ†æå®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ åˆ†ææ•°æ®æ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ å›¾åƒæ•°æ®ç»“æ„åˆ†æå·¥å…·")
    print("="*60)
    
    # æ•°æ®è·¯å¾„
    data_path = "/home/xuxuezhou/code/RoboTwin/data/move_can_pot/integration.pkl"
    
    # åˆ†æå›¾åƒæ•°æ®
    analyze_image_data_structure(data_path)

if __name__ == "__main__":
    main() 